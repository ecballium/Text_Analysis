test_sum <- distinct(test_sum)
if (dim(test_sum)[1]!=(length(unique(test_sum$words)))){
stop("Something went wrong in the processing")
}
test_sum <- test_sum %>% mutate(SAT=replace(SAT, is.na(SAT), 0))
test_sum <- as.data.frame(test_sum) #Seems to be necessary
test_sum <- test_sum %>% arrange(desc(SAT), desc(MP)) %>% mutate(SAT_Rank = row_number())
#Some hopeless attempts
#test_sum <- as.data.frame(test_sum) #Seems to be necessary
#test_sum <- test_sum %>% mutate(SAT_Rank = dense_rank(c(SAT, MP)) )
#max_SAT_Rank <- max(test_sum$SAT_Rank)
#test_sum <- test_sum %>% mutate(SAT2 = case_when(is.na(SAT) ~ dense_rank(desc(MP))))
#test_sum <- test_sum %>% mutate(SAT3 = dense_rank(interaction(SAT, MP)))
test_sum <- as.data.frame(test_sum)
#test_sum <- test_sum %>% mutate(H_Rank = dense_rank(desc(H)))
test_sum <- test_sum %>% mutate(H_Rank = row_number(desc(H)))
test_sum <- test_sum %>% mutate(Tot_Rank = SAT_Rank+ H_Rank)
test_sum <- test_sum %>% arrange(Tot_Rank)
#' A note on ordering:
#'
#' - decreasing entropy (stopwords have highest entropy)
#' - decreasing SAT_Rank (stopwords have high MP and low VP)
#' NOTE: in case of the same SAT values, MP is taken into account
x
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x
x <- gsub("\\]","],",x)
x
strsplit(x,",")
scan(text=   # use scan to separate after insertion of commas
gsub("\\]", "],",   # put commas in after "]"'s
gsub(".\\[", ",[",  x)) ,  # add commas before "[" unless at first position
what="", sep=",")
strsplit(as.character(120:125), "")
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- strsplit(x,",")
ind <- grepl("[.*]", x)
y <- character()
for (a in seq_along(x)){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], sep = "")))
}
}
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- strsplit(x,",")
ind <- grepl("[.*]", x)
y <- character()
for (a in seq_along(x)){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], split = "")))
}
}
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- strsplit(x,",")
ind <- grepl("[.*]", x)
y <- character()
for (a in seq_along(x)){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
}
x
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- strsplit(x,",")
ind <- grepl("[.*]", x)
y <- character()
for (a in seq_along(x)){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
print(y)
}
x
length(x[[1]])
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- unlist(strsplit(x,","))
ind <- grepl("[.*]", x)
y <- character()
for (a in seq_along(x)){
#if (nchar)
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
print(y)
}
ind
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- unlist(strsplit(x,","))
ind <- grepl("\\[.*\\]", x)
y <- character()
for (a in seq_along(x)){
#if (nchar)
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
print(y)
}
x <- "[a] + [bc] + 1"
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- unlist(strsplit(x,","))
ind <- grepl("\\[.*\\]", x)
y <- character()
for (a in seq_along(x)){
if (nchar(x[a])!=0){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
}
print(y)
}
foo <- function(x){
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- unlist(strsplit(x,","))
ind <- grepl("\\[.*\\]", x)
y <- character()
for (a in seq_along(x)){
if (nchar(x[a])!=0){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
}
print(y)
}
return(y)
}
foo("cd/etc/init[BKSP][BKSP]it.d[ENTER]")
sth <- foo("cd/etc/init[BKSP][BKSP]it.d[ENTER]")
sth
foo <- function(x){
x <- gsub("\\[",",[",x)
x <- gsub("\\]","],",x)
x <- unlist(strsplit(x,","))
ind <- grepl("\\[.*\\]", x)
y <- character()
for (a in seq_along(x)){
if (nchar(x[a])!=0){
if (ind[a]){
y <- c(y, x[a])
} else {
y <- c(y, unlist(strsplit(x[a], "")))
}
}
#print(y)
}
y <- gsub("\\[", "", y)
y <- gsub("\\]", "", y)
return(y)
}
sth <- foo("cd/etc/init[BKSP][BKSP]it.d[ENTER]")
sth
View(test_sum)
#'
#' # Stoplist Analysis
#'
#' ## Setup
#+
library(dplyr)
#'
#' ## Test case
#'
#+
#N <- 3
#test <- data.frame(words = c("a", "b", "c", "a", "b", "b", "d"),
#                   freq = c(5, 3, 4, 2, 3, 8, 2),
#                   doc = c(rep("i", 3), rep("ii", 2), rep("iii", 2)))
#test <- data.frame(words = c("a", "b", "c", "e", "a", "b", "b", "d"),
#                   freq = c(3, 5, 4, 1, 2, 3, 8, 2),
#                   doc = c(rep("i", 4), rep("ii", 2), rep("iii", 2)))
#'
#' ## Data Preprocessing
#'
#'
#+
T <- readLines(con <- file("ogt_utf.txt", encoding = "UTF-8"))
N <- 10
Tp <- divideCharVector(T, N)
counts_df <- data.frame()
#for (i in 1){
for (i in 1:N){
c <- table(unlist(strsplit(Tp[[i]], split="")))
c <- c[order(c, decreasing = TRUE)]
c <- as.data.frame(c, stringsAsFactors = FALSE)
c$doc <- i
colnames(c) <- c("words", "freq", "doc")
counts_df <- rbind(counts_df, c)
}
test <- counts_df
#'
#'
#'
#' ## Calculations
#'
#+
#Calculate Doc_size (sum freq within a doc)
test <- test %>% group_by(doc) %>% mutate(Doc_size = sum(freq))
#Calculate Prob_word_in_doc (freq/Doc_size)
test <- test %>% group_by(words) %>% mutate(Prob_word_in_doc = freq/Doc_size)
#Calculate MP ((sum of prob)/N)
test <- test %>% group_by(words) %>% mutate(MP = sum(Prob_word_in_doc)/N)
#Calculate Variance (divided by the number of documents)
test <- test %>% group_by(words) %>% mutate(VP = var(Prob_word_in_doc)/N)
#Calculate SAT
test <- mutate(test, SAT = MP/VP)
#Calculate Entropy (in two steps)
#test <- mutate(test, H_int = -(Prob_word_in_doc * log(Prob_word_in_doc, base = 2)))
#test <- test %>% group_by(words) %>% mutate(H2 = sum(H_int))
#Calculate Entropy
test <- test %>% group_by(words) %>% mutate(H = sum(-Prob_word_in_doc * log(Prob_word_in_doc, base = 2)))
test_sum <- test %>% select(words, MP, VP, SAT, H)
test_sum <- distinct(test_sum)
if (dim(test_sum)[1]!=(length(unique(test_sum$words)))){
stop("Something went wrong in the processing")
}
test_sum <- test_sum %>% mutate(SAT=replace(SAT, is.na(SAT), 0))
test_sum <- as.data.frame(test_sum) #Seems to be necessary
test_sum <- test_sum %>% arrange(desc(SAT), desc(MP)) %>% mutate(SAT_Rank = row_number())
#Some hopeless attempts
#test_sum <- as.data.frame(test_sum) #Seems to be necessary
#test_sum <- test_sum %>% mutate(SAT_Rank = dense_rank(c(SAT, MP)) )
#max_SAT_Rank <- max(test_sum$SAT_Rank)
#test_sum <- test_sum %>% mutate(SAT2 = case_when(is.na(SAT) ~ dense_rank(desc(MP))))
#test_sum <- test_sum %>% mutate(SAT3 = dense_rank(interaction(SAT, MP)))
test_sum <- as.data.frame(test_sum)
#test_sum <- test_sum %>% mutate(H_Rank = dense_rank(desc(H)))
test_sum <- test_sum %>% mutate(H_Rank = row_number(desc(H)))
test_sum <- test_sum %>% mutate(Tot_Rank = SAT_Rank+ H_Rank)
test_sum <- test_sum %>% arrange(Tot_Rank)
#' A note on ordering:
#'
#' - decreasing entropy (stopwords have highest entropy)
#' - decreasing SAT_Rank (stopwords have high MP and low VP)
#' NOTE: in case of the same SAT values, MP is taken into account
View(test_sum)
2^(0.5)
2^0.5
#'
#' # Stoplist Analysis
#'
#' ## Setup
#+
library(dplyr)
#'
#' ## Test case
#'
#+
#N <- 3
#test <- data.frame(words = c("a", "b", "c", "a", "b", "b", "d"),
#                   freq = c(5, 3, 4, 2, 3, 8, 2),
#                   doc = c(rep("i", 3), rep("ii", 2), rep("iii", 2)))
#test <- data.frame(words = c("a", "b", "c", "e", "a", "b", "b", "d"),
#                   freq = c(3, 5, 4, 1, 2, 3, 8, 2),
#                   doc = c(rep("i", 4), rep("ii", 2), rep("iii", 2)))
#'
#' ## Data Preprocessing
#'
#'
#+
T <- readLines(con <- file("ogt_utf.txt", encoding = "UTF-8"))
N <- 10
Tp <- divideCharVector(T, N)
counts_df <- data.frame()
#for (i in 1){
for (i in 1:N){
c <- table(unlist(strsplit(Tp[[i]], split="")))
c <- c[order(c, decreasing = TRUE)]
c <- as.data.frame(c, stringsAsFactors = FALSE)
c$doc <- i
colnames(c) <- c("words", "freq", "doc")
counts_df <- rbind(counts_df, c)
}
test <- counts_df
#'
#'
#'
#' ## Calculations
#'
#+
#Calculate Doc_size (sum freq within a doc)
test <- test %>% group_by(doc) %>% mutate(Doc_size = sum(freq))
#Calculate Prob_word_in_doc (freq/Doc_size)
test <- test %>% group_by(words) %>% mutate(Prob_word_in_doc = freq/Doc_size)
#Calculate MP ((sum of prob)/N)
test <- test %>% group_by(words) %>% mutate(MP = sum(Prob_word_in_doc)/N)
#Calculate Variance (divided by the number of documents)
test <- test %>% group_by(words) %>% mutate(VP = var(Prob_word_in_doc)/N)
#Calculate SAT
#test <- mutate(test, SAT = MP/VP)
test <- mutate(test, SAT = MP/(VP^0.5))
#Calculate Entropy (in two steps)
#test <- mutate(test, H_int = -(Prob_word_in_doc * log(Prob_word_in_doc, base = 2)))
#test <- test %>% group_by(words) %>% mutate(H2 = sum(H_int))
#Calculate Entropy
test <- test %>% group_by(words) %>% mutate(H = sum(-Prob_word_in_doc * log(Prob_word_in_doc, base = 2)))
test_sum <- test %>% select(words, MP, VP, SAT, H)
test_sum <- distinct(test_sum)
if (dim(test_sum)[1]!=(length(unique(test_sum$words)))){
stop("Something went wrong in the processing")
}
test_sum <- test_sum %>% mutate(SAT=replace(SAT, is.na(SAT), 0))
test_sum <- as.data.frame(test_sum) #Seems to be necessary
test_sum <- test_sum %>% arrange(desc(SAT), desc(MP)) %>% mutate(SAT_Rank = row_number())
#Some hopeless attempts
#test_sum <- as.data.frame(test_sum) #Seems to be necessary
#test_sum <- test_sum %>% mutate(SAT_Rank = dense_rank(c(SAT, MP)) )
#max_SAT_Rank <- max(test_sum$SAT_Rank)
#test_sum <- test_sum %>% mutate(SAT2 = case_when(is.na(SAT) ~ dense_rank(desc(MP))))
#test_sum <- test_sum %>% mutate(SAT3 = dense_rank(interaction(SAT, MP)))
test_sum <- as.data.frame(test_sum)
#test_sum <- test_sum %>% mutate(H_Rank = dense_rank(desc(H)))
test_sum <- test_sum %>% mutate(H_Rank = row_number(desc(H)))
test_sum <- test_sum %>% mutate(Tot_Rank = SAT_Rank+ H_Rank)
test_sum <- test_sum %>% arrange(Tot_Rank)
#' A note on ordering:
#'
#' - decreasing entropy (stopwords have highest entropy)
#' - decreasing SAT_Rank (stopwords have high MP and low VP)
#' NOTE: in case of the same SAT values, MP is taken into account
#'
#' # Stoplist Analysis
#'
#' ## Setup
#+
library(dplyr)
#'
#' ## Test case
#'
#+
#N <- 3
#test <- data.frame(words = c("a", "b", "c", "a", "b", "b", "d"),
#                   freq = c(5, 3, 4, 2, 3, 8, 2),
#                   doc = c(rep("i", 3), rep("ii", 2), rep("iii", 2)))
#test <- data.frame(words = c("a", "b", "c", "e", "a", "b", "b", "d"),
#                   freq = c(3, 5, 4, 1, 2, 3, 8, 2),
#                   doc = c(rep("i", 4), rep("ii", 2), rep("iii", 2)))
#'
#' ## Data Preprocessing
#'
#'
#+
T <- readLines(con <- file("ogt_utf.txt", encoding = "UTF-8"))
N <- 10
Tp <- divideCharVector(T, N)
counts_df <- data.frame()
#for (i in 1){
for (i in 1:N){
c <- table(unlist(strsplit(Tp[[i]], split="")))
c <- c[order(c, decreasing = TRUE)]
c <- as.data.frame(c, stringsAsFactors = FALSE)
c$doc <- i
colnames(c) <- c("words", "freq", "doc")
counts_df <- rbind(counts_df, c)
}
test <- counts_df
#'
#'
#'
#' ## Calculations
#'
#+
#Calculate Doc_size (sum freq within a doc)
test <- test %>% group_by(doc) %>% mutate(Doc_size = sum(freq))
#Calculate Prob_word_in_doc (freq/Doc_size)
test <- test %>% group_by(words) %>% mutate(Prob_word_in_doc = freq/Doc_size)
#Calculate MP ((sum of prob)/N)
test <- test %>% group_by(words) %>% mutate(MP = sum(Prob_word_in_doc)/N)
#Calculate Variance (divided by the number of documents)
test <- test %>% group_by(words) %>% mutate(VP = var(Prob_word_in_doc)/N)
#Calculate SAT
#test <- mutate(test, SAT = MP/VP) #Does not work very well
#test <- mutate(test, SAT = MP/(VP^0.5))
test <- mutate(test, SAT = MP*(VP^0.5))
#Calculate Entropy (in two steps)
#test <- mutate(test, H_int = -(Prob_word_in_doc * log(Prob_word_in_doc, base = 2)))
#test <- test %>% group_by(words) %>% mutate(H2 = sum(H_int))
#Calculate Entropy
test <- test %>% group_by(words) %>% mutate(H = sum(-Prob_word_in_doc * log(Prob_word_in_doc, base = 2)))
test_sum <- test %>% select(words, MP, VP, SAT, H)
test_sum <- distinct(test_sum)
if (dim(test_sum)[1]!=(length(unique(test_sum$words)))){
stop("Something went wrong in the processing")
}
test_sum <- test_sum %>% mutate(SAT=replace(SAT, is.na(SAT), 0))
test_sum <- as.data.frame(test_sum) #Seems to be necessary
test_sum <- test_sum %>% arrange(desc(SAT), desc(MP)) %>% mutate(SAT_Rank = row_number())
#Some hopeless attempts
#test_sum <- as.data.frame(test_sum) #Seems to be necessary
#test_sum <- test_sum %>% mutate(SAT_Rank = dense_rank(c(SAT, MP)) )
#max_SAT_Rank <- max(test_sum$SAT_Rank)
#test_sum <- test_sum %>% mutate(SAT2 = case_when(is.na(SAT) ~ dense_rank(desc(MP))))
#test_sum <- test_sum %>% mutate(SAT3 = dense_rank(interaction(SAT, MP)))
test_sum <- as.data.frame(test_sum)
#test_sum <- test_sum %>% mutate(H_Rank = dense_rank(desc(H)))
test_sum <- test_sum %>% mutate(H_Rank = row_number(desc(H)))
test_sum <- test_sum %>% mutate(Tot_Rank = SAT_Rank+ H_Rank)
test_sum <- test_sum %>% arrange(Tot_Rank)
#' A note on ordering:
#'
#' - decreasing entropy (stopwords have highest entropy)
#' - decreasing SAT_Rank (stopwords have high MP and low VP)
#' NOTE: in case of the same SAT values, MP is taken into account
test_sum$VP[7]
100000000000000000
library(ggplot2)
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(0,1000000)) + xlim(c(0, 0.01))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(0,0.0000001)) + xlim(c(0, 0.01))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(0,0.000000001)) + xlim(c(0, 0.01))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(0,0.000000001)) + xlim(c(0, 0.001))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(0,0.000000001)) + xlim(c(0, 0.0005))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(0,0.000000001)) + xlim(c(0, 0.0003))
summary(test_sum$MP)
summary(test_sum$MP)[2]
MP_1q <- summary(test_sum$MP)[2]
MP_3q <- summary(test_sum$MP)[5]
VP_1q <- summary(test_sum$VP)[2]
VP_3q <- summary(test_sum$VP)[5]
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = H)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))
knitr::spin("Scripts/Stoplist_Analysis_Full.R")
knitr::spin("Scripts/Stoplist_Analysis_Full.R")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(fill = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))
library(RColorBrewer)
coul = brewer.pal(4, "BuPu")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))
coul = brewer.pal(4, "BuPu")
coul = colorRampPalette(coul)
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))
str(coul)
View(coul)
coul = brewer.pal(4, "BuPu")
coul
coul = colorRampPalette(coul)
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_color_brewer()
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_fill_brewer()
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_fill_brewer(palette = "Greens")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_fill_distiller(palette = "Greens")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradient2()
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradient2(colours = terrain.colors(5))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradient2(colours = terrain.colors(10))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradient2(colours = terrain.colors())
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradient2(colours = terrain.colors(4))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradient2(colours = terrain.colors(n = 4))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colours = terrain.colors(3))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colours = Spectral(3))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colours = terrain.colors(3))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colours = "Spectral")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn("Spectral")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(palete = "Spectral")
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(terrain.colors(5))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colors = terrain.colors(5))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colors = magenta2green(5))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = Tot_Rank)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q)) + scale_colour_gradientn(colors = heat.colors(5))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = H)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = H)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))+ scale_colour_gradientn(colors = terrain.colors(15))
ggplot(test_sum, aes(x = MP, y = VP)) + geom_point(aes(col = H)) + ylim(c(VP_1q, VP_3q)) + xlim(c(MP_1q, MP_3q))+ scale_colour_gradientn(colors = terrain.colors(100))
knitr::spin("Scripts/Stoplist_Analysis_Full.R")
sessionInfo()
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(aes(col = MP))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(aes(col = MP)) + scale_colour_gradientn(colors = heat.colors(5))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(aes(col = MP)) + scale_colour_gradientn(colors = heat.colors(15))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(aes(col = MP)) + scale_colour_gradientn(colors = terrain.colors(15))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02)
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02)+ scale_colour_brewer(palette="Oranges")
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(aes(col = MP)) + scale_colour_gradientn(coul)
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(aes(col = MP)) + scale_colour_gradientn(colors = coul)
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02)
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02) + scale_color_gradient(low = "green", high = "red")
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_color_gradient(low = "green", high = "red")
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_color_gradient(breaks = c(0, MP_1q, MP_3q))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_color_gradient(colors = light.terrain, breaks = c(0, MP_1q, MP_3q))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_color_gradient(colors = terrain.colors, breaks = c(0, MP_1q, MP_3q))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_color_gradient(breaks = c(0, MP_1q))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_fill_manual(values = coul)
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + scale_fill_manual(values = c("red", "white", 'blue'))
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(0, 0.01))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + sc
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(0, 0.001))
ggplot(test_sum, aes(x = SAT_Rank, y = H_Rank)) + geom_point(size = 0.02, aes(col = MP)) + sc
knitr::spin("Scripts/Stoplist_Analysis_Full.R")
