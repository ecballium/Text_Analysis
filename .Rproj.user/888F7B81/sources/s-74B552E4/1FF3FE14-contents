
---
title: "Our Glamorous Times - Analysis"
output:
  html_notebook:
    code_folding: none
    toc: yes
    toc_float: yes
  html_document:
    toc: yes
    toc_float: yes
---


#Reading text files
All files were encoded using UTF-8 (ASCII insufficient, plain Unicode somehow problematic).
```{r}
A <- readLines(con <- file("test_eng_utf.txt", encoding = "UTF-8"))

C <- readLines(con <- file("test_ch_utf.txt", encoding = "UTF-8"))

C1 <- readLines(con <- file("ch1.txt", encoding = "UTF-8"))

T <- readLines(con <- file("ogt_utf.txt", encoding = "UTF-8"))

```

##Displaying characters

Changing these settings allows viewing Chinese characters in the data frame viewer in RStudio.

```{r}
#Sys.setlocale(locale = "Chinese") #Choose Chinese
#Sys.setlocale() #Revert back to original when finished
```


#Most common words

```{r}
single_counts <- table(unlist(strsplit(T, split="")))

single_counts <- single_counts[order(single_counts, decreasing = TRUE)]
```



```{r}
single_counts[1:100]
```



```{r}
saveRDS(single_counts, "single_counts.Rda")
```



#Most common pairs of words

##Method
Developing the tools

###A method for splitting vectors into pairs of words
https://stackoverflow.com/questions/2247045/chopping-a-string-into-a-vector-of-fixed-width-character-elements 
```{r}
x <- "xxyyxyxy"
sst <- strsplit(x, "")[[1]]
paste0(sst[c(TRUE, FALSE)], sst[c(FALSE, TRUE)])
```


###Expanding the method to include all possible pairs

On good track, but repeats the final character (need to control the parity of the input)
```{r}
x <- "xxyyxyxy"
sst <- unlist(strsplit(x, ""))
sst <- sst[2:length(sst)]
paste0(sst[c(TRUE, FALSE)], sst[c(FALSE, TRUE)])
```




###Analysing required functionality

Case 1: Even characters  
Original string: KLMNOP  
Without first char: LMNOP  
First pass: KL, MN, OP  
Second pass: LM, NO, P(P)  


Case 2: Odd characters  
Original string: ABCDEFG  
Without first char: BCDEFG  
First pass: AB, CD, EF, G(G)  
Second pass: BC, DE, FG  

Case 3: Even plus .  
KLMNOP.  
LMNOP.  
KL, MN, OP, .(.)  
LM, NO, P.  

case 4: Odd plus .  
ABCDEFG.  
BCDEFG.  
AB, CD, EF, G.  
BC, DE, FG, .(.)  


For even numbers: remove last pair from the SECOND pass
For odd numbers: remove last pair from the FIRST pass

###Function

```{r}
ch2split <- function(x){
  if (length(x)>1){
    stop("Vectors are not allowed")
  }
  if (nchar(x)!=0){
    x1 <- unlist(strsplit(x, split=""))
    x2 <- x1[-1] #Need to take empty vectors into account
    
    w1 <- paste0(x1[c(TRUE, FALSE)], x1[c(FALSE, TRUE)])
    w2 <- paste0(x2[c(TRUE, FALSE)], x2[c(FALSE, TRUE)])
    
    if(length(x1)%%2==1){
      w1 <- w1[1:length(w1)-1]
    }
    
    if(length(x1)%%2==0){
      w2 <- w2[1:length(w2)-1]
    }
    
    #unwanted <- “，！…”
    
    unwanted <- "\\p{P}"
    
    w1 <- w1[!grepl(unwanted, w1, perl=TRUE)]
    w2 <- w2[!grepl(unwanted, w2, perl=TRUE)]
    return(c(w1,w2))
  } else {
    return("")
  }

}
```


##Basic case

###Workflow

```{r}
words <- sapply(T, ch2split)
names(words) <- NULL
words <- unlist(words)

words_counts <- table(words)
words_counts <- words_counts[order(words_counts, decreasing = TRUE)]

words_counts <- as.data.frame(words_counts)

#Remove unwanted entries
words_counts <- words_counts[!(words_counts$words==""),] #Empty strings
words_counts <- words_counts[!grepl("[[:alnum:]]", words_counts$words),] #Numbers and letters
```

###Save results

```{r}
saveRDS(words_counts, "words_counts.Rda")
```


###Visualisation

```{r}
#library(ggplot2)
qplot(y=words_counts$Freq, x=1:length(words_counts$Freq))
```


```{r}
library(ggplot2)

#Initial approaches
ggplot(words_counts, aes(x = words_counts$Freq)) + geom_freqpoly()

ggplot(words_counts, aes(x = log(words_counts$Freq))) + geom_freqpoly() #Rather dodgy approach with log (should be log counts, not log frequency)


```


```{r}
#Best so far
ggplot(words_counts, aes(Freq)) +
geom_histogram(binwidth = 50) + scale_y_log10()
```

##Excluding the top 100 commmonest characters
Rationale: words which do not contain top 100 characters are more likely to be actual words rather than frequent combinations of individual characters.


###weliminate() - Function for finding indices of interest


```{r}
weliminate <- function(elim, x){
  #To include some statements to prevent the possibility of input (x) being a matrix/df
  y <- replicate(length(x), TRUE)
  for (e in seq_along(elim)){
    y <- y & !grepl(elim[e], x)
  }
  return(y)
}
```


###Workflow

```{r}
top100 <- as.data.frame(single_counts[1:100], stringsAsFactors = FALSE)
colnames(top100) <- c("words", "Freq")
top100 <- top100$words

words_counts_no100 <- words_counts[weliminate(top100, words_counts$words),]
```

##Examining results

```{r}
#T[grep("目光", T)][1:50]
```


